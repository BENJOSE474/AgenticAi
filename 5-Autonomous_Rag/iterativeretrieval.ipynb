{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b08010f5",
   "metadata": {},
   "source": [
    "### üîÅ What is Iterative Retrieval in Agentic RAG?\n",
    "Combined both Iterative And Self reflection\n",
    "\n",
    "‚úÖ Definition:\n",
    "Iterative Retrieval is a dynamic strategy where an AI agent doesn't settle for the first batch of retrieved documents. Instead, it evaluates the adequacy of the initial context, and if necessary, it:\n",
    "\n",
    "- Refines the query,\n",
    "- Retrieves again,\n",
    "- Repeats the process until it‚Äôs confident enough to answer the original question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da34940e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import StateGraph, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "608c9bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "llm=init_chat_model(\"openai:gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12a5543b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load And Embed Documents\n",
    "docs = TextLoader(\"research_notes.txt\", encoding=\"utf-8\").load()\n",
    "chunks = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50).split_documents(docs)\n",
    "vectorstore = FAISS.from_documents(chunks, OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11e4b011",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Agent State\n",
    "\n",
    "class IterativeRAGState(BaseModel):\n",
    "    question: str\n",
    "    refined_question: str = \"\"\n",
    "    retrieved_docs: List[Document] = []\n",
    "    answer: str = \"\"\n",
    "    verified: bool = False\n",
    "    attempts: int = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0323e527",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Retrieve Node\n",
    "def retrieve_docs(state: IterativeRAGState) -> IterativeRAGState:\n",
    "    query = state.refined_question or state.question\n",
    "    docs = retriever.invoke(query)\n",
    "    return state.model_copy(update={\"retrieved_docs\": docs})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82acec3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reflect And Verify\n",
    "def generate_answer(state: IterativeRAGState) -> IterativeRAGState:\n",
    "    \n",
    "    context = \"\\n\\n\".join(doc.page_content for doc in state.retrieved_docs)\n",
    "    prompt = f\"\"\"Use the following context to answer the question:\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{state.question}\n",
    "\"\"\"\n",
    "    response = llm.invoke(prompt.strip()).content.strip()\n",
    "    return state.model_copy(update={\"answer\": response, \"attempts\": state.attempts + 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91b389c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reflect on answer\n",
    "def reflect_on_answer(state: IterativeRAGState) -> IterativeRAGState:\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "Evaluate whether the answer below is factually sufficient and complete.\n",
    "\n",
    "Question: {state.question}\n",
    "Answer: {state.answer}\n",
    "\n",
    "Respond 'YES' if it's complete, otherwise 'NO' with feedback.\n",
    "\"\"\"\n",
    "    feedback = llm.invoke(prompt).content.lower()\n",
    "    verified = \"yes\" in feedback\n",
    "    return state.model_copy(update={\"verified\": verified})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c0e11cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Refine query\n",
    "def refine_query(state: IterativeRAGState) -> IterativeRAGState:\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "The answer appears incomplete. Suggest a better version of the query that would help retrieve more relevant context.\n",
    "\n",
    "Original Question: {state.question}\n",
    "Current Answer: {state.answer}\n",
    "\"\"\"\n",
    "    new_query = llm.invoke(prompt).content.strip()\n",
    "    return state.model_copy(update={\"refined_question\": new_query})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c0924d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(IterativeRAGState)\n",
    "\n",
    "builder.add_node(\"retrieve\", retrieve_docs)\n",
    "builder.add_node(\"answer\", generate_answer)\n",
    "builder.add_node(\"reflect\", reflect_on_answer)\n",
    "builder.add_node(\"refine\", refine_query)\n",
    "\n",
    "builder.set_entry_point(\"retrieve\")\n",
    "builder.add_edge(\"retrieve\", \"answer\")\n",
    "builder.add_edge(\"answer\", \"reflect\")\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"reflect\",\n",
    "    lambda s: END if s.verified or s.attempts >= 2 else \"refine\"\n",
    ")\n",
    "\n",
    "builder.add_edge(\"refine\", \"retrieve\")\n",
    "builder.add_edge(\"answer\", END)\n",
    "\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa9f0967",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(IterativeRAGState)\n",
    "\n",
    "builder.add_node(\"retrieve\", retrieve_docs)\n",
    "builder.add_node(\"answer\", generate_answer)\n",
    "builder.add_node(\"reflect\", reflect_on_answer)\n",
    "builder.add_node(\"refine\", refine_query)\n",
    "\n",
    "builder.set_entry_point(\"retrieve\")\n",
    "builder.add_edge(\"retrieve\", \"answer\")\n",
    "builder.add_edge(\"answer\", \"reflect\")\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"reflect\",\n",
    "    lambda s: END if s.verified or s.attempts >= 2 else \"refine\"\n",
    ")\n",
    "\n",
    "builder.add_edge(\"refine\", \"retrieve\")\n",
    "builder.add_edge(\"answer\", END)\n",
    "\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84dc7091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Final Answer:\n",
      " Agent loops and transformer-based systems often work in tandem to enhance the capabilities of AI-driven applications, particularly in tasks requiring dynamic interactions and complex computations. Here's how they relate to the context provided:\n",
      "\n",
      "1. **Transformer-Based Systems:**\n",
      "   - Transformers like TinyBERT, EfficientFormer, and Longformer are pivotal in handling various tasks due to their ability to process and understand language at a sophisticated level.\n",
      "   - TinyBERT, for instance, is used for classification tasks like support ticket priority tagging and demonstrates high efficiency with domain adaptation through a 2-layer FFN adapter.\n",
      "   - Systems like EfficientFormer and Longformer are optimized for specific use cases such as image recognition and handling longer text sequences, respectively.\n",
      "\n",
      "2. **Agent Loops:**\n",
      "   - These involve repetitive cycles of receiving input, processing it, and producing output, which might include interactions with external tools or conducting specific reasoning operations.\n",
      "   - The context mentions tool-augmented prompting (e.g., dynamic retrieval-agent reasoning through LangGraph + Wikipedia + SQL search), suggesting that agent loops are enhanced by transformers' ability to integrate and reason over multiple information sources.\n",
      "\n",
      "3. **Integration examples:**\n",
      "   - LLaMA2 integrates FlashAttention2 for reduced context latency, making real-time or streaming interactions more feasible, which can be crucial in agent loops where quick turnaround is necessary.\n",
      "   - Chain-of-Thought and reflective prompting in such systems enhance reasoning and accuracy, crucial for tasks where agents need to deduce or infer information across multiple steps.\n",
      "\n",
      "In essence, transformer-based systems provide the backbone for processing and reasoning in AI models, while agent loops dictate how these processes are orchestrated within applications, particularly where ongoing interaction or real-time decision-making is vital.\n",
      "\n",
      "üß† Verified: False\n",
      "üîÅ Attempts: 2\n"
     ]
    }
   ],
   "source": [
    "query = \"agent loops  and transformer-based systems?\"\n",
    "\n",
    "initial_state = IterativeRAGState(question=query)\n",
    "final = graph.invoke(initial_state)\n",
    "\n",
    "print(\"‚úÖ Final Answer:\\n\", final[\"answer\"])\n",
    "print(\"\\nüß† Verified:\", final[\"verified\"])\n",
    "print(\"üîÅ Attempts:\", final[\"attempts\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
